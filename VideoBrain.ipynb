{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "2G4eac-JlAez"
      },
      "outputs": [],
      "source": [
        "\"\"\"requirements.txt:- pip install -r requirements.txt\n",
        "pytubefix\n",
        "langchain\n",
        "faiss-cpu\n",
        "sentence-transformers\n",
        "openai\n",
        "gradio\n",
        "tiktoken\"\"\"\n",
        "from pytubefix import YouTube\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import TextLoader\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#!pip install -U -r requirements.txt\n",
        "#!pip install -U langchain-community pytubefix langchain faiss-cpu sentence-transformers openai gradio tiktoken\"\"\""
      ],
      "metadata": {
        "id": "FYOx-kLvM6h9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "71f994a4-606b-41fe-b334-232875c61db0"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#!pip install -U -r requirements.txt\\n#!pip install -U langchain-community pytubefix langchain faiss-cpu sentence-transformers openai gradio tiktoken'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa = None\n",
        "\n",
        "# Step 1: Download & Clean Transcript\n",
        "def download_and_clean_transcript(url, output_path=\"transcript.txt\"):\n",
        "    yt = YouTube(url)\n",
        "    caption = yt.captions.get_by_language_code('en') or yt.captions.get_by_language_code('a.en')\n",
        "\n",
        "    if caption:\n",
        "        srt_captions = caption.generate_srt_captions()\n",
        "        srt_lines = srt_captions.splitlines()\n",
        "\n",
        "        clean_lines = []\n",
        "        for line in srt_lines:\n",
        "            line = line.strip()\n",
        "            if line.isdigit() or '-->' in line or line == '':\n",
        "                continue\n",
        "            clean_lines.append(line)\n",
        "\n",
        "        with open(output_path, 'w', encoding='utf-8') as file:\n",
        "            for line in clean_lines:\n",
        "                file.write(line + '\\n')\n",
        "\n",
        "        return \"Transcript cleaned and saved successfully!\"\n",
        "    else:\n",
        "        return \"English or auto-generated English captions not found.\"\n"
      ],
      "metadata": {
        "id": "sR78QcdIIoS8"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_doc_setup():\n",
        "    path = \"transcript.txt\"\n",
        "    loader = TextLoader(path, encoding=\"utf-8\")\n",
        "    documents = loader.load()\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    chunks = splitter.split_documents(documents)\n",
        "\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
        "\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    llm = ChatOpenAI(\n",
        "        model=\"llama3-8b-8192\",\n",
        "        openai_api_key=\"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\",\n",
        "        openai_api_base=\"https://api.groq.com/openai/v1\",\n",
        "        temperature=0.4,\n",
        "    )\n",
        "    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n"
      ],
      "metadata": {
        "id": "oZ6XQdGj27fY"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_video(url):\n",
        "    status = download_and_clean_transcript(url)\n",
        "    if \"successfully\" not in status:\n",
        "        return status\n",
        "\n",
        "    global qa\n",
        "    qa = chat_with_doc_setup()\n",
        "    return qa.run(\"Summarize this YouTube video like a course breakdown. Include the key topics covered, practical tips, learning advice. Be clear, structured, and helpful for a beginner.\")"
      ],
      "metadata": {
        "id": "JpawT7kvK-8D"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_question_about_video(question, history):\n",
        "    global qa\n",
        "    if qa is None:\n",
        "        return [(\"System\", \"Please summarize a video first.\")], \"\"\n",
        "    answer = qa.run(question)\n",
        "    history = history or []\n",
        "    history.append((question, answer))\n",
        "    return history, \"\""
      ],
      "metadata": {
        "id": "ZiILA8mwK_pT"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "231BgaIsNNBY"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_logo_html = \"\"\"\n",
        "<div style=\"display: flex; align-items: center; gap: 10px; padding: 10px; background-color: #181818; color: white;\">\n",
        "    <svg height=\"30\" viewBox=\"0 0 24 24\" width=\"30\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
        "        <rect x=\"1.5\" y=\"1.5\" width=\"21\" height=\"21\" rx=\"4\" stroke=\"#FFA500\" stroke-width=\"2\"/>\n",
        "        <polygon points=\"10,8 16,12 10,16\" fill=\"#800080\"/>\n",
        "    </svg>\n",
        "    <h1 style=\"font-size: 24px; font-weight: 600; margin: 0;\">VideoBrain</h1>\n",
        "</div>\n",
        "\"\"\"\n",
        "from huggingface_hub import create_repo\n",
        "with gr.Blocks() as demo:\n",
        "    gr.HTML(custom_logo_html)\n",
        "    gr.Markdown(\"## Created by Krishna Bhat U\")\n",
        "    youtube_url = gr.Textbox(label=\"Enter YouTube Video Link\")\n",
        "    summarize_button = gr.Button(\"Summarize\")\n",
        "    summary_output = gr.Textbox(label=\"üìù Video Summary\", lines=20)\n",
        "\n",
        "    gr.Markdown(\"## üí¨ Q&A Chat\")\n",
        "\n",
        "    chat_history = gr.Chatbot()\n",
        "    question_input = gr.Textbox(label=\"Ask a question about the video\")\n",
        "    ask_button = gr.Button(\"Send\")\n",
        "\n",
        "\n",
        "    summarize_button.click(fn=summarize_video, inputs=youtube_url, outputs=summary_output)\n",
        "    ask_button.click(fn=ask_question_about_video, inputs=[question_input, chat_history], outputs=[chat_history, question_input])\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "DToxVJWZLCMk",
        "outputId": "57f59e67-2b82-48ec-8ace-4335652ff2ed"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-145-8e0dd07652d3>:20: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chat_history = gr.Chatbot()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://dec0685edbb5c7c98e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://dec0685edbb5c7c98e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    }
  ]
}